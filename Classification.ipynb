{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the differnt emotions in the files\n",
    "emotions = ['anxiety', 'boredom', 'cold-anger', 'contempt', 'despair', 'disgust', 'elation', 'happy',\n",
    "            'hot-anger', 'interest', 'neutral', 'panic',    'pride',    'sadness', 'shame']\n",
    "clr =      [\"red\",  \"cyan\",   \"orange\",  \"purple\",   \"magenta\", \"green\",    \"yellow\",  \"pink\",\n",
    "            \"yellow\", \"green\", \"magenta\", \"purple\",  \"orange\", \"cyan\",      \"red\"]\n",
    "\n",
    "speakers = ['mf_001', 'cc_001', 'jg_001', 'mm_001', 'cl_001', 'gg_001', 'mk_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to opensmile\n",
    "smile = \"/opensmile-2.3.0/inst/bin\"\n",
    "cwd = os.getcwd()\n",
    "toFiles = cwd + \"/speech_files/\"\n",
    "\n",
    "\n",
    "run = './SMILExtract'\n",
    "conf = '../../config/IS09_emotion.conf'\n",
    "output = \"myfeatureset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the names of the files\n",
    "names = []\n",
    "# change directory to opensmile\n",
    "os.chdir(smile)\n",
    "# batching processing the audio file\n",
    "# all the files should be contained in the folder called speech_files\n",
    "for wave_file in glob.glob(toFiles + \"*.wav\"):\n",
    "    \n",
    "    name = wave_file.split(\"/\")[-1][:len(wave_file.split(\"/\")[-1])-4]\n",
    "    print(\"Processing {}...\".format(name))\n",
    "#     print(run , '-C' , conf ,  '-I' , wave_file, '-csvoutput', output)\n",
    "    p = subprocess.Popen([run , '-C' , conf ,  '-I' , wave_file, '-csvoutput', output])\n",
    "    names.append(name)\n",
    "    p.wait()\n",
    "\n",
    "# reading the final feature file    \n",
    "data = pd.read_csv(output, sep=';')\n",
    "\n",
    "#changing names of the file\n",
    "print(\"number of files processed and featuresized: \", len(names))\n",
    "for x in range(len(names)):\n",
    "    data['name'][x] = names[x]\n",
    "\n",
    "# change back directory\n",
    "os.chdir(cwd)\n",
    "\n",
    "#saving file\n",
    "data.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = {'p':[], 'nb':[], 'r':[], 'c':[], 's':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c199512711cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeakers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mspk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdata' is not defined"
     ]
    }
   ],
   "source": [
    "# one speaker out cross validation\n",
    "# get the data for test and train\n",
    "for spk in speakers:\n",
    "    \n",
    "    test = [[],[]]\n",
    "    train = [[],[]]\n",
    "    \n",
    "    for sp in speakers:\n",
    "        if sp == spk:\n",
    "            test[0] = test[0] + sdata[sp][0]\n",
    "            test[1] = test[1] + sdata[sp][1]\n",
    "        else:\n",
    "            train[0] = train[0] + sdata[sp][0]\n",
    "            train[1] = train[1] + sdata[sp][1]\n",
    "\n",
    "    print('test speaker: ', spk)\n",
    "\n",
    "    testX = np.array(test[1])\n",
    "    trainX = np.array(train[1])\n",
    "    \n",
    "\n",
    "    trainY = []\n",
    "    testY = []\n",
    "\n",
    "    for x in range(len(train[0])):\n",
    "        e = train[0][x]\n",
    "        trainY.append(emotions.index(e))\n",
    "\n",
    "    for x in range(len(test[0])):\n",
    "        e = test[0][x]\n",
    "        testY.append(emotions.index(e))\n",
    "\n",
    "    trainY = np.array(trainY)\n",
    "    testY = np.array(testY)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #multilayer perceptron\n",
    "    mlf = MLPClassifier(hidden_layer_sizes=(250,500,150, 100), activation='tanh',\n",
    "                        max_iter=500, alpha=0.0001,learning_rate=\"adaptive\",\n",
    "                        learning_rate_init=0.0001,solver='sgd', verbose=False,  \n",
    "                        random_state=110,tol=0.000000000001, nesterovs_momentum=True, warm_start=True)\n",
    "   \n",
    "    mlf.fit(trainX, trainY)\n",
    "    y_pred = mlf.predict(testX)\n",
    "    print('perceptron', spk)\n",
    "    rep = classification_report(testY, y_pred, target_names=emotions)\n",
    "    print(rep)\n",
    "    reports['p'].append(rep)\n",
    "    \n",
    "    \n",
    "#     # SVM\n",
    "#     clf = LinearSVC(random_state=0, tol=1e-5, max_iter=2000)\n",
    "#     clf.fit(trainX, trainY)\n",
    "#     y_pred = clf.predict(testX)\n",
    "#     print(classification_report(testY, y_pred, target_names=emotions))\n",
    "  \n",
    "    \n",
    "    #Ridge Regression\n",
    "    rlf = RidgeClassifier( max_iter=100000).fit(trainX, trainY)\n",
    "    y_pred = rlf.predict(testX)\n",
    "    print('Ridge', spk)\n",
    "    rep = classification_report(testY, y_pred, target_names=emotions)\n",
    "    print(rep)\n",
    "    reports['r'].append(rep)\n",
    "    \n",
    "    # Naive Bayes Gaussian\n",
    "    glf = GaussianNB().fit(trainX, trainY)\n",
    "    y_pred = glf.predict(testX)\n",
    "    print('naive bayes', spk)\n",
    "    rep = classification_report(testY, y_pred, target_names=emotions)\n",
    "    print(rep)\n",
    "    reports['nb'].append(rep)\n",
    "    \n",
    "    \n",
    "    # nearest centroid\n",
    "    cnlf = NearestCentroid().fit(trainX, trainY)\n",
    "    y_pred = cnlf.predict(testX)\n",
    "    print('centroid', spk)\n",
    "    rep = classification_report(testY, y_pred, target_names=emotions)\n",
    "    print(rep)\n",
    "    reports['c'].append(rep)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
